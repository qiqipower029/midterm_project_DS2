---
title: "Linear classification and trees"
author: "Jieqi Tu (jt3098)"
date: "5/13/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(AppliedPredictiveModeling)
library(pROC)
```


#Load and tidy data
```{r}
#read data
rawdata <- read.csv("kc_house_data.csv", header = TRUE)

#inspect the structure of data
str(rawdata)
```


```{r}
#clean the rawdata; create a tidied dataset for analysis and modelling.
#subset data: only those with view >0 and basement >0.
housing = 
  rawdata %>% 
  select(-id, -date, -zipcode, -lat, -long) %>% 
  filter(view > 0, bedrooms <30) %>% 
  mutate(basement = ifelse(sqft_basement == 0, 0, 1),
         renovated = ifelse(yr_renovated == 0, 0, 1)) %>% 
  filter(basement > 0) %>% 
  select(-sqft_basement, -yr_renovated, -view, - sqft_living, -sqft_lot, -basement) 

# dichotimize response variable
median(housing$price) #805000
housing <- housing %>% mutate(price.new = ifelse(price>805000, "High", "Low")) 
housing$price.new <- factor(housing$price.new, c("High", "Low"))
# create training data and testing data.
rowTrain <- createDataPartition(y = housing$price, 
                                p=0.8, list = FALSE)
```

# Data visuailization
```{r data visualization for linear classification}
transparentTheme(trans = 0.4)
featurePlot(x = housing[,2:12],
            y = housing$price.new,
            scales = list(x = list(relation = "free"),
                          y = list(relation = "free")),
            plot = "density", pch = "|",
            auto.key = list(columns = 2))
```

From the feature plot we could see that, the two classes of price are distributed differently in features. 

# Logistic Regression
```{r logistic regression}
# Use caret package
ctrl = trainControl(method = "cv",
                    summaryFunction = twoClassSummary,
                    classProbs = T)
set.seed(1)
model.glm = train(x = housing[rowTrain, 2:12],
                  y = housing$price.new[rowTrain],
                  method = "glm",
                  metric = "ROC",
                  trControl = ctrl)
# test performance
pred.glm = predict(model.glm, newdata = housing[-rowTrain,2:13], response = "prob")
pred.glm.prob = predict(model.glm, newdata = housing[-rowTrain,2:13], type = "prob")
confusionMatrix(data = as.factor(pred.glm), reference = housing$price.new[-rowTrain])

# plot the ROC curve
roc.glm = roc(housing$price.new[-rowTrain], pred.glm.prob$High)
plot(roc.glm, legacy.axes = T, print.auc = T)
plot(smooth(roc.glm), col = 4, add = T)
```

The AUC is 0.943. The accuracy is 0.8676. Sensitivity is 0.8042, Specificity is 0.9306.

```{r regularized logistic regression}
glmnGrid = expand.grid(.alpha = seq(0, 1, length = 8),
                       .lambda = exp(seq(-5, -1, length = 20)))
set.seed(1)
model.glmn = train(x = housing[rowTrain, 2:12],
                   y = housing$price.new[rowTrain],
                   method = "glmnet",
                   tuneGrid = glmnGrid,
                   metric = "ROC",
                   trControl = ctrl)

plot(model.glmn, xTrans = function(x) log(x))

pred.glmn = predict(model.glmn, newdata = housing[-rowTrain, 2:13], type = "prob")
```


# Discriminant Analysis
```{r LDA using caret}
set.seed(1)
model.lda = train(x = housing[rowTrain, 2:12],
                  y = housing$price.new[rowTrain],
                  method = "lda",
                  metric = "ROC",
                  trControl = ctrl)
pred.lda = predict(model.lda, newdata = housing[-rowTrain,2:13], type = "prob")
roc.lda = roc(housing$price.new[-rowTrain], pred.lda$High, levels = c("High", "Low"))
plot(roc.lda, legacy.axes = T, print.auc = T)
```

The AUC for LDA is 0.933.

```{r QDA using caret package}
set.seed(1)
model.qda = train(x = housing[rowTrain, 2:12],
                  y = housing$price.new[rowTrain],
                  method = "qda",
                  metric = "ROC",
                  trControl = ctrl)

pred.qda = predict(model.qda, newdata = housing[-rowTrain, 2:13], type = "prob")
roc.qda = roc(housing$price.new[-rowTrain], pred.qda$High, levels = c("High", "Low"))
plot(roc.qda, legacy.axes = T, print.auc = T)
```

The AUC for QDA is 0.889.

```{r KNN using caret}
set.seed(1)
model.knn = train(x = housing[rowTrain, 2:12],
                  y = housing$price.new[rowTrain],
                  method = "knn",
                  preProcess = c("center", "scale"),
                  metric = "ROC",
                  tuneGrid = data.frame(k = seq(1, 200, by = 5)),
                  trControl = ctrl)
ggplot(model.knn) + theme_bw()

pred.knn = predict(model.knn, newdata = housing[-rowTrain, 2:13], type = "prob")
```

```{r Naive Bayes using caret, message=FALSE, warning=FALSE}
set.seed(1)
nbGrid = expand.grid(usekernel = c(FALSE, TRUE),
                     fL = 0,
                     adjust = seq(0, 5, by = 1))
housing = na.omit(housing)

model.nb = train(x = housing[rowTrain, 2:12],
                 y = housing$price.new[rowTrain],
                 method = "nb",
                 metric = "ROC",
                 tuneGrid = nbGrid,
                 trControl = ctrl)

pred.nb = predict(model.nb, newdata = housing[-rowTrain, 2:13], type = "prob")
plot(model.nb)
```

### Model Comparism
```{r compare models}
res = resamples(list(GLM = model.glm, LDA = model.lda, QDA = model.qda, NB = model.nb, KNN = model.knn))

summary(res)
```

GLM and LDA tend to have higher AUC values.

```{r test performance}
roc.glmn = roc(housing$price.new[-rowTrain], pred.glmn[,2])
roc.nb = roc(housing$price.new[-rowTrain], pred.nb[,2])
roc.knn = roc(housing$price.new[-rowTrain], pred.knn[,2])

auc = c(roc.glm$auc[1], roc.glmn$auc[1], roc.lda$auc[1],
        roc.qda$auc[1], roc.lda$auc[1], roc.knn$auc[1])

plot(roc.glm, legacy.axes = T)
plot(roc.glmn, col = 2, add = T)
plot(roc.lda, col = 3, add = T)
plot(roc.qda, col = 4, add = T)
plot(roc.nb, col = 5, add = T)
plot(roc.knn, col = 6, add = T)
modelNames = c("glm", "glmn", "lda", "qda", "nb", "knn")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc, 3)), col = 1:6, lwd = 2)
```

### Regression Trees
```{r the CART approach}
set.seed(1)
library(rpart.plot)
housing = 
  rawdata %>% 
  dplyr::select(-id, -date, -zipcode, -lat, -long) %>% 
  filter(view > 0, bedrooms <30) %>% 
  mutate(basement = ifelse(sqft_basement == 0, 0, 1),
         renovated = ifelse(yr_renovated == 0, 0, 1)) %>% 
  filter(basement > 0) %>% 
  dplyr::select(-sqft_basement, -yr_renovated, -view, - sqft_living, -sqft_lot, -basement) 
housing = na.omit(housing)

ctrl1 = trainControl(method = "cv", number = 10)
rpart.fit = train(price~., housing,
                  method = "rpart",
                  tuneGrid = data.frame(cp = exp(seq(-20, -5, length = 20))),
                  trControl = ctrl1)

ggplot(rpart.fit, highlight = T) + theme_bw()

rpart.fit$finalModel$cptable
rpart.plot(rpart.fit$finalModel)

# 1se rule
rpart.fit.1se = train(price~., housing,
                  method = "rpart",
                  tuneGrid = data.frame(cp = exp(seq(-20, -5, length = 20))),
                  trControl = trainControl(method = "cv", number = 10, selectionFunction = "oneSE"))

rpart.fit.1se$finalModel$cptable
rpart.plot(rpart.fit.1se$finalModel)
```

The 1se rule provided a much more simple model.

```{r tune over maximum depth}
# tune over maximum depth, method = "rpart2"
set.seed(1)
rpart2.fit = train(price~., housing,
                   method = "rpart2",
                   tuneGrid = data.frame(maxdepth = 1:12),
                   trControl = ctrl1)
ggplot(rpart2.fit, highlight = T) + theme_bw()
rpart.plot(rpart2.fit$finalModel)
rpart2.fit$finalModel$cptable
```

```{r conditional inference tree}
# fit a conditional inference tree
set.seed(1)
ctree.fit = train(price~., housing,
                  method = "ctree",
                  tuneGrid = data.frame(mincriterion = 1 - exp(seq(-6, -2, length = 20))),
                  trControl = ctrl1)
ggplot(ctree.fit, highlight = T) + theme_bw()
plot(ctree.fit$finalModel)
```

### Ensemble Methods

Bagging and Random forests

```{r bagging}
# bagging
bagging.grid = expand.grid(mtry = 11,
                           splitrule = "variance", 
                           min.node.size = 1:30)
set.seed(1)
bagging.fit = train(price~., housing,
                    method = "ranger",
                    tuneGrid = bagging.grid,
                    trControl = ctrl1,
                    importance = "impurity")

ggplot(bagging.fit, highlight = T) + theme_bw()

# check variable importance
barplot(sort(ranger::importance(bagging.fit$finalModel), decreasing = FALSE),
        las = 2, horiz = T, cex.names = 0.7,
        col = colorRampPalette(colors = c("darkred", "white", "darkblue"))(19))
```

The most important variables are grade, the area above and the area of living room.

```{r ranger}
# ranger
rf.grid = expand.grid(mtry = 1:5, splitrule = "variance",
                      min.node.size = 1:10)
set.seed(1)
rf.fit = train(price~., housing,
               method = "ranger",
               tuneGrid = rf.grid,
               trControl = ctrl1,
               importance = "impurity")

ggplot(rf.fit, highlight = T) + theme_bw()

# check variable importance
barplot(sort(ranger::importance(rf.fit$finalModel), decreasing = FALSE),
        las = 2, horiz = T, cex.names = 0.7,
        col = colorRampPalette(colors = c("darkred", "white", "darkblue"))(19))
```

When p = 4, minimal node size = 6, we get the lowest RMSE value. The importance is the same as bagging.

```{r boosting}
# boosting
set.seed(1)
gbm.grid = expand.grid(n.trees = c(2000, 3000, 5000),
                       interaction.depth = 1:10,
                       shrinkage = c(0.001, 0.003, 0.005),
                       n.minobsinnode = 1)
gbm.fit = train(price~., housing,
                method = "gbm",
                tuneGrid = gbm.grid,
                trControl = ctrl1,
                verbose = FALSE)

ggplot(gbm.fit, highlight = T) + theme_bw()

# check variable importance
summary(gbm.fit$finalModel, las = 2, cBars = 19, cex.names = 0.6)
```

### Model comparism
```{r compare regression classification models}
# compare cross-validation performance of models
resamp = resamples(list(rf = rf.fit, bagging = bagging.fit, gbm = gbm.fit))
summary(resamp)
```

