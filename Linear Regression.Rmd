---
title: "Linear Regression"
author: "Jieqi Tu (jt3098)"
date: "3/26/2019"
output: pdf_document
---


#Load and tidy data
```{r}
#read data
rawdata <- read.csv("kc_house_data.csv", header = TRUE)

#inspect the structure of data
str(rawdata)
```

  `id`, `date`, `zipcode`, `lat`, `long` can be removed from the dataframe.   
  The cleaned dataset to be used in this project include one response variable `price` and additional 15 variables.  
  `view`, `sqft_basement` and `yr_renovated` are continuous or integer variables in the original dataset. For the purpose of easy interpretation in later modelling, we convert these variables to be binary. Then these variables indicate whether the house has been viewed by potential buyers, whether the house has basement or not and whether the house has been renovated or not, respectively.  

```{r}
#clean the rawdata; create a tidied dataset for analysis and modelling.
#subset data: only those with view >0.
housing = 
  rawdata %>% select(-id, -date, -zipcode, -lat, -long) %>% 
  filter(view > 0 & bedrooms <30) %>% 
  mutate(basement = ifelse(sqft_basement == 0, 0, 1),
         renovated = ifelse(yr_renovated == 0, 0, 1)) %>% 
  select(-sqft_basement, -yr_renovated, -view) 
```

#Exploratory data analysis
## Continuous variables
```{r}
# vector of response
y <- housing$price

# matrix of continuous predictors 
housing_continous = housing %>% select(c(price, sqft_living, grade, sqft_above, yr_built, sqft_living15, floors, condition, bedrooms, bathrooms, sqft_living, sqft_lot ))
x_continuous <- model.matrix(price~., housing_continous)[,-1]

# set up the theme of plotting
theme1 <- trellis.par.get()   
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

featurePlot(x_continuous, y, plot = "scatter", labels = c("","Y"),
            type = c("p"), layout = c(3, 4))
```


## Binary variables
```{r}
# dataframe of binary predictors 
housing_binary = housing %>% 
  select(c(price,view, waterfront, basement, renovated )) %>%
  mutate(view = as.factor(view),
         waterfront = as.factor(waterfront),
         basement = as.factor(basement),
         renovated = as.factor(renovated)) 

# boxplots
par(mfrow = c(2, 2))
boxplot(price~view, data=housing_binary, ylab = "Price", xlab ="View") 
boxplot(price~waterfront, data=housing_binary, ylab = "Price", xlab ="waterfront") 
boxplot(price~basement, data=housing_binary, ylab = "Price", xlab ="basement") 
boxplot(price~renovated, data=housing_binary, ylab = "Price", xlab ="renovated") 
```


# Model Building
#### Linear model
```{r least square model using caret package}
# build a least-square linear model
ctrl1 = trainControl(method = "repeatedcv", number = 10, repeats = 5)
x = model.matrix(price~., housing)[,-1]
set.seed(1)
library(MASS)
lm_fit = lm(price~., data = housing)
boxcox = boxcox(lm_fit)
best.lambda = boxcox$x[which(boxcox$y==max(boxcox$y))]; best.lambda
step(lm_fit, direction = 'backward')
model_ls = train(x, y,
                 method = "lm",
                 preProcess = c("center", "scale"),
                 trControl = ctrl1)
summary(model_ls)

```

```{r ridge model building using caret package}
set.seed(1)
# fit a ridge model using caret package
ridge.fit = train(x, y,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 0,
                                         lambda = exp(seq(-2, 15, length = 10))),
                  preProcess = c("center", "scale", "BoxCox"),
                  trControl = ctrl1)

# plot the RMSE by log(lambda)
plot(ridge.fit, xTrans = function(x) log(x))

# find the optimal lambda
ridge.fit$bestTune

# obtain the coefficients of ridge model
coef(ridge.fit$finalModel, ridge.fit$bestTune$lambda)
```

```{r lasso model building using caret package}
# fit a lasso model using caret
set.seed(1)
lasso.fit = train(x, y,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 1,
                                         lambda = exp(seq(-1, 12, length = 100))),
                  preProcess = c("center", "scale", "BoxCox"),
                  trControl = ctrl1)

# plot the RMSE by log(lambda)
plot(lasso.fit, xTrans = function(x) log(x))

# obtain the optimal lambda
lasso.fit$bestTune

# check the coefficients for each predictors
coef(lasso.fit$finalModel, lasso.fit$bestTune$lambda)
```

```{r compare these linear models}
set.seed(1)
resamp = resamples(list(lasso = lasso.fit, ridge = ridge.fit, lm = model_ls))
summary(resamp)
bwplot(resamp, metric = "RMSE")
```

